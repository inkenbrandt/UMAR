{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import arcpy\n",
    "import urllib2\n",
    "from pyproj import Proj, transform\n",
    "import xmltodict\n",
    "import mechanize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Import and Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rootname = \"/media/p/5F5B-8FCB/PROJECTS/UMAR/Phase_II/Data/chem/\" #thumb on ubuntu\n",
    "rootname = \"E:\\\\PROJECTS\\\\UMAR\\\\Phase_II\\\\Data\\\\chem\\\\\" #thumb on windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WQPResultsFile = rootname + \"result.csv\"\n",
    "WQPStationFile = rootname + \"station.csv\"\n",
    "SDWISFile = rootname + \"SDWIS_Cache.txt\"\n",
    "AGStationsFile = rootname + \"AG_Stations_Cache.csv\"\n",
    "AGResultsFile = rootname + \"AG_byparam.csv\"\n",
    "UGSFile = rootname + \"UGS_Cache.txt\"\n",
    "STORLegStatFile = rootname + \"UT_Cache_sta_001.txt\"\n",
    "STORLegResFile = rootname + \"UT_Cache_res_001.txt\"\n",
    "STORParamFile = rootname + \"parameter.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fielddata = rootname + \"FieldData.xlsx\"\n",
    "statelabresults0 = rootname + \"utgs1402.txt\"\n",
    "statelabresults1 = rootname + \"utgs1403.txt\"\n",
    "statelabresults2 = rootname + \"utgs1501.txt\"\n",
    "statelabstations = rootname + \"UtahStateLabStations.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##WQP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://waterqualitydata.us/Station/search?statecode=US%3A49&countycode=US%3A49%3A005&sampleMedia=Water&characteristicType=Information%3BInorganics%2C+Major%2C+Metals%3BInorganics%2C+Major%2C+Non-metals%3BInorganics%2C+Minor%2C+Metals%3BInorganics%2C+Minor%2C+Non-metals%3BNot+Assigned%3BNutrient%3BPhysical%3BStable+Isotopes&mimeType=csv&zip=yes&sorted=no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "http://waterqualitydata.us/Result/search?statecode=US%3A49&countycode=US%3A49%3A005&sampleMedia=Water&characteristicType=Information%3BInorganics%2C+Major%2C+Metals%3BInorganics%2C+Major%2C+Non-metals%3BInorganics%2C+Minor%2C+Metals%3BInorganics%2C+Minor%2C+Non-metals%3BNot+Assigned%3BNutrient%3BPhysical%3BStable+Isotopes&mimeType=csv&zip=yes&sorted=no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rdtypes = {\"OrganizationIdentifier\":np.str_, \"OrganizationFormalName\":np.str_, \"ActivityIdentifier\":np.str_, \n",
    "           \"ActivityStartTime/Time\":np.str_,\n",
    "           \"ActivityTypeCode\":np.str_, \"ActivityMediaName\":np.str_, \"ActivityMediaSubdivisionName\":np.str_, \n",
    "           \"ActivityStartDate\":np.str_, \"ActivityStartTime/Time\":np.str_, \"ActivityStartTime/TimeZoneCode\":np.str_, \n",
    "           \"ActivityEndDate\":np.str_, \"ActivityEndTime/Time\":np.str_, \"ActivityEndTime/TimeZoneCode\":np.str_, \n",
    "           \"ActivityDepthHeightMeasure/MeasureValue\":np.float16, \"ActivityDepthHeightMeasure/MeasureUnitCode\":np.str_, \n",
    "           \"ActivityDepthAltitudeReferencePointText\":np.str_, \"ActivityTopDepthHeightMeasure/MeasureValue\":np.float16, \n",
    "           \"ActivityTopDepthHeightMeasure/MeasureUnitCode\":np.str_, \n",
    "           \"ActivityBottomDepthHeightMeasure/MeasureValue\":np.float16, \n",
    "           \"ActivityBottomDepthHeightMeasure/MeasureUnitCode\":np.str_, \n",
    "           \"ProjectIdentifier\":np.str_, \"ActivityConductingOrganizationText\":np.str_, \n",
    "           \"MonitoringLocationIdentifier\":np.str_, \"ActivityCommentText\":np.str_, \n",
    "           \"SampleAquifer\":np.str_, \"HydrologicCondition\":np.str_, \"HydrologicEvent\":np.str_, \n",
    "           \"SampleCollectionMethod/MethodIdentifier\":np.str_, \"SampleCollectionMethod/MethodIdentifierContext\":np.str_, \n",
    "           \"SampleCollectionMethod/MethodName\":np.str_, \"SampleCollectionEquipmentName\":np.str_, \n",
    "           \"ResultDetectionConditionText\":np.str_, \"CharacteristicName\":np.str_, \"ResultSampleFractionText\":np.str_, \n",
    "           \"ResultMeasureValue\":np.str_, \"ResultMeasure/MeasureUnitCode\":np.str_, \"MeasureQualifierCode\":np.str_, \n",
    "           \"ResultStatusIdentifier\":np.str_, \"StatisticalBaseCode\":np.str_, \"ResultValueTypeName\":np.str_, \n",
    "           \"ResultWeightBasisText\":np.str_, \"ResultTimeBasisText\":np.str_, \"ResultTemperatureBasisText\":np.str_, \n",
    "           \"ResultParticleSizeBasisText\":np.str_, \"PrecisionValue\":np.str_, \"ResultCommentText\":np.str_, \n",
    "           \"USGSPCode\":np.str_, \"ResultDepthHeightMeasure/MeasureValue\":np.float16, \n",
    "           \"ResultDepthHeightMeasure/MeasureUnitCode\":np.str_, \"ResultDepthAltitudeReferencePointText\":np.str_, \n",
    "           \"SubjectTaxonomicName\":np.str_, \"SampleTissueAnatomyName\":np.str_, \n",
    "           \"ResultAnalyticalMethod/MethodIdentifier\":np.str_, \"ResultAnalyticalMethod/MethodIdentifierContext\":np.str_, \n",
    "           \"ResultAnalyticalMethod/MethodName\":np.str_, \"MethodDescriptionText\":np.str_, \"LaboratoryName\":np.str_, \n",
    "           \"AnalysisStartDate\":np.str_, \"ResultLaboratoryCommentText\":np.str_, \n",
    "           \"DetectionQuantitationLimitTypeName\":np.str_, \"DetectionQuantitationLimitMeasure/MeasureValue\":np.str_, \n",
    "           \"DetectionQuantitationLimitMeasure/MeasureUnitCode\":np.str_, \"PreparationStartDate\":np.str_, \n",
    "           \"ProviderName\":np.str_} \n",
    "\n",
    "dt = [6,56,61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WQP = pd.read_csv(WQPResultsFile, dtype=Rdtypes, parse_dates=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ResFieldDict = {\"AnalysisStartDate\":\"AnalysisDate\", \"ResultAnalyticalMethod/MethodIdentifier\":\"AnalytMeth\", \n",
    "                \"ResultAnalyticalMethod/MethodName\":\"AnalytMethId\", \"ResultDetectionConditionText\":\"DetectCond\", \n",
    "                \"ResultLaboratoryCommentText\":\"LabComments\", \"LaboratoryName\":\"LabName\", \n",
    "                \"DetectionQuantitationLimitTypeName\":\"LimitType\", \"DetectionQuantitationLimitMeasure/MeasureValue\":\"MDL\", \n",
    "                \"DetectionQuantitationLimitMeasure/MeasureUnitCode\":\"MDLUnit\", \"MethodDescriptionText\":\"MethodDescript\", \n",
    "                \"OrganizationIdentifier\":\"OrgId\", \"OrganizationFormalName\":\"OrgName\", \"CharacteristicName\":\"Param\", \n",
    "                \"ProjectIdentifier\":\"ProjectId\", \"MeasureQualifierCode\":\"QualCode\", \"ResultCommentText\":\"ResultComment\", \n",
    "                \"ResultStatusIdentifier\":\"ResultStatus\", \"ResultMeasureValue\":\"ResultValue\", \n",
    "                \"ActivityCommentText\":\"SampComment\", \"ActivityDepthHeightMeasure/MeasureValue\":\"SampDepth\", \n",
    "                \"ActivityDepthAltitudeReferencePointText\":\"SampDepthRef\", \n",
    "                \"ActivityDepthHeightMeasure/MeasureUnitCode\":\"SampDepthU\", \"SampleCollectionEquipmentName\":\"SampEquip\", \n",
    "                \"ResultSampleFractionText\":\"SampFrac\", \"ActivityStartDate\":\"SampleDate\", \"ActivityIdentifier\":\"SampleId\", \n",
    "                \"ActivityStartTime/Time\":\"SampleTime\", \"ActivityMediaSubdivisionName\":\"SampMedia\", \n",
    "                \"SampleCollectionMethod/MethodIdentifier\":\"SampMeth\", \"SampleCollectionMethod/MethodName\":\"SampMethName\", \n",
    "                \"ActivityTypeCode\":\"SampType\", \"MonitoringLocationIdentifier\":\"StationId\", \n",
    "                \"ResultMeasure/MeasureUnitCode\":\"Unit\", \"USGSPCode\":\"USGSPCode\",\n",
    "                \"ActivityStartDate\":\"StartDate\",\"ActivityStartTime/Time\":\"StartTime\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WQP.rename(columns=ResFieldDict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resdroplist = [\"ActivityBottomDepthHeightMeasure/MeasureUnitCode\", \"ActivityBottomDepthHeightMeasure/MeasureValue\", \n",
    "               \"ActivityConductingOrganizationText\", \"ActivityEndDate\", \"ActivityEndTime/Time\", \n",
    "               \"ActivityEndTime/TimeZoneCode\", \"ActivityMediaName\", \"ActivityStartTime/TimeZoneCode\", \n",
    "               \"ActivityTopDepthHeightMeasure/MeasureUnitCode\", \"ActivityTopDepthHeightMeasure/MeasureValue\", \n",
    "               \"HydrologicCondition\", \"HydrologicEvent\", \"PrecisionValue\", \"PreparationStartDate\", \"ProviderName\", \n",
    "               \"ResultAnalyticalMethod/MethodIdentifierContext\", \"ResultDepthAltitudeReferencePointText\", \n",
    "               \"ResultDepthHeightMeasure/MeasureUnitCode\", \"ResultDepthHeightMeasure/MeasureValue\", \n",
    "               \"ResultParticleSizeBasisText\", \"ResultTemperatureBasisText\", \n",
    "               \"ResultTimeBasisText\", \"ResultValueTypeName\", \"ResultWeightBasisText\", \"SampleAquifer\", \n",
    "               \"SampleCollectionMethod/MethodIdentifierContext\", \"SampleTissueAnatomyName\", \"StatisticalBaseCode\", \n",
    "               \"SubjectTaxonomicName\",\"StartTime\",\"StartDate\",\"StartTime\",\"StartDate\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def datetimefix(x,format):\n",
    "    d = str(x[0]).lstrip().rstrip()[0:10]\n",
    "    t = str(x[1]).lstrip().rstrip()[0:5].zfill(5)\n",
    "    try:\n",
    "        int(d[0:2])\n",
    "    except(ValueError,TypeError,NameError):\n",
    "        return np.nan\n",
    "    try:\n",
    "        int(t[0:2])\n",
    "        int(t[3:5])\n",
    "    except(ValueError,TypeError,NameError):\n",
    "        t = \"00:00\"\n",
    "   \n",
    "    if int(t[0:2])>23:\n",
    "        t = \"00:00\"\n",
    "    elif int(t[3:5])>59:\n",
    "        t = \"00:00\"\n",
    "    else:\n",
    "        t = t[0:2].zfill(2) + \":\" + t[3:5]\n",
    "    return datetime.datetime.strptime(d + \" \" + t, format)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WQP[\"SampleDate\"] = WQP[[\"StartDate\",\"StartTime\"]].apply(lambda x: datetimefix(x,\"%Y-%m-%d %H:%M\"),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WQP.drop(resdroplist,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WQP['ResultValue'] = WQP['ResultValue'].convert_objects(convert_numeric=True)\n",
    "WQP['MDL'] = WQP['MDL'].convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WQP['StationId'] = WQP['StationId'].str.replace('_WQX-','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unitfix(x):\n",
    "    z = str(x).lower()\n",
    "    if z == \"ug/l\":\n",
    "        return \"mg/l\"\n",
    "    elif z == \"mg/l\":\n",
    "        return \"mg/l\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "WQP.Unit = WQP.Unit.apply(lambda x: str(x).rstrip(), 1)\n",
    "WQP.ResultValue = WQP[[\"ResultValue\",\"Unit\"]].apply(lambda x: x[0]/1000 if str(x[1]).lower()==\"ug/l\" else x[0], 1)\n",
    "WQP.Unit = WQP.Unit.apply(lambda x: unitfix(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parnorm(x):\n",
    "    p = str(x[0]).rstrip().lstrip().lower()\n",
    "    u = str(x[2]).rstrip().lstrip().lower()\n",
    "    if p == 'nitrate' and u == 'mg/l as n':\n",
    "        return 'Nitrate', x[1]*4.427, 'mg/l'\n",
    "    elif p == 'nitrite' and u == 'mg/l as n':\n",
    "        return 'Nitrite', x[1]*3.285, 'mg/l'\n",
    "    elif p == 'ammonia-nitrogen' or p == 'ammonia-nitrogen as n' or p == 'ammonia and ammonium':\n",
    "        return 'Ammonium', x[1]*1.288, 'mg/l'\n",
    "    elif p == 'ammonium' and u == 'mg/l as n':\n",
    "        return 'Ammonium', x[1]*1.288, 'mg/l'\n",
    "    elif p == 'sulfate as s':\n",
    "        return 'Sulfate', x[1]*2.996, 'mg/l'\n",
    "    elif p in ('phosphate-phosphorus', 'phosphate-phosphorus as p','orthophosphate as p'):\n",
    "        return 'Phosphate', x[1]*3.066, 'mg/l'\n",
    "    elif (p == 'phosphate' or p == 'orthophosphate') and u == 'mg/l as p':\n",
    "        return 'Phosphate', x[1]*3.066, 'mg/l'\n",
    "    elif u == 'ug/l':\n",
    "        return x[0], x[1]/1000, 'mg/l'\n",
    "    else:\n",
    "        return x[0], x[1], str(x[2]).rstrip()\n",
    "\n",
    "WQP['Param'], WQP['ResultValue'], WQP['Unit'] = zip(*WQP[['Param','ResultValue','Unit']].apply(lambda x: parnorm(x),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WQPStat = pd.read_csv(WQPStationFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StatFieldDict = {\"MonitoringLocationIdentifier\":\"StationId\", \"AquiferName\":\"Aquifer\", \"AquiferTypeName\":\"AquiferType\", \n",
    "             \"ConstructionDateText\":\"ConstDate\", \"CountyCode\":\"CountyCode\", \"WellDepthMeasure/MeasureValue\":\"Depth\", \n",
    "             \"WellDepthMeasure/MeasureUnitCode\":\"DepthUnit\", \"VerticalMeasure/MeasureValue\":\"Elev\", \n",
    "             \"VerticalAccuracyMeasure/MeasureValue\":\"ElevAcc\", \"VerticalAccuracyMeasure/MeasureUnitCode\":\"ElevAccUnit\", \n",
    "             \"VerticalCollectionMethodName\":\"ElevMeth\", \"VerticalCoordinateReferenceSystemDatumName\":\"ElevRef\", \n",
    "             \"VerticalMeasure/MeasureUnitCode\":\"ElevUnit\", \"FormationTypeText\":\"FmType\", \n",
    "             \"WellHoleDepthMeasure/MeasureValue\":\"HoleDepth\", \"WellHoleDepthMeasure/MeasureUnitCode\":\"HoleDUnit\", \n",
    "             \"HorizontalAccuracyMeasure/MeasureValue\":\"HorAcc\", \"HorizontalAccuracyMeasure/MeasureUnitCode\":\"HorAccUnit\", \n",
    "             \"HorizontalCollectionMethodName\":\"HorCollMeth\", \"HorizontalCoordinateReferenceSystemDatumName\":\"HorRef\", \n",
    "             \"HUCEightDigitCode\":\"HUC8\", \"LatitudeMeasure\":\"Lat_Y\", \"LongitudeMeasure\":\"Lon_X\", \n",
    "             \"OrganizationIdentifier\":\"OrgId\", \"OrganizationFormalName\":\"OrgName\", \"StateCode\":\"StateCode\", \n",
    "             \"MonitoringLocationDescriptionText\":\"StationComment\", \"MonitoringLocationName\":\"StationName\", \n",
    "             \"MonitoringLocationTypeName\":\"StationType\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WQPStat.rename(columns=StatFieldDict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statdroplist = [\"ContributingDrainageAreaMeasure/MeasureUnitCode\", \"ContributingDrainageAreaMeasure/MeasureValue\", \n",
    "                \"DrainageAreaMeasure/MeasureUnitCode\", \"DrainageAreaMeasure/MeasureValue\", \"CountryCode\", \"ProviderName\", \n",
    "                \"SourceMapScaleNumeric\"]\n",
    "WQPStat.drop(statdroplist,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TypeDict = {\"Stream: Canal\":\"Stream\", \"River/Stream\":\"Stream\", \n",
    "            \"Stream: Canal\":\"Stream\", \"Well: Test hole not completed as a well\":\"Well\"}\n",
    "WQPStat.StationType = WQPStat[\"StationType\"].apply(lambda x: TypeDict.get(x,x),1)\n",
    "WQPStat.Elev = WQPStat.Elev.apply(lambda x: np.nan if x==0.0 else round(x,1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WQPStat['StationId'] = WQPStat['StationId'].str.replace('_WQX-','-')\n",
    "WQPStat.drop_duplicates(subset=['StationId'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##SDWIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDWIS data were extracted from the Utah SDWIS database into ArcGIS 10.3.2 using the following SQL query.  NED 10m elevation and UTM coordinates were appended using ArcGIS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT UTV80.TINWSF.EXTERNAL_SYS_NUM AS \"FED_NM\",  UTV80.TINWSF.ST_ASGN_IDENT_CD AS \"ST_ID\",  UTV80.TINWSF.TYPE_CODE,  UTV80.TINWSYS.NAME AS \"SYS_NM\", UTV80.TINWSYS.D_PRIN_CNTY_SVD_NM AS \"COUNTY\", UTV80.TINWSF.NAME AS \"FAC_NM\",  UTV80.TINWSF.TINWSYS_IS_NUMBER AS \"SY_NBR\", UTV80.TINLOC.LATITUDE_MEASURE AS \"Y\",  UTV80.TINLOC.LONGITUDE_MEASURE AS \"X\",  UTV80.TINLOC.VERTICAL_MEASURE AS \"Z\", UTV80.TSASAMPL.COLLLECTION_END_DT AS \"DTE\", UTV80.TSAANLYT.NAME AS \"ANLY_NM\",  UTV80.TSASAR.CONCENTRATION_MSR AS \"CONC_MSR\", UTV80.TSASAR.TSASAR_IS_NUMBER AS \"ID_NUM\",  UTV80.TSASAR.UOM_CODE,   UTV80.TSASAR.DETECTN_LIMIT_NUM AS \"DET_LIM\", UTV80.TSASAR.DETECTN_LIM_UOM_CD AS \"DET_UOM\"  FROM  UTV80.TINWSF  INNER JOIN  UTV80.TINWSYS ON UTV80.TINWSF.TINWSYS_IS_NUMBER = UTV80.TINWSYS.TINWSYS_IS_NUMBER  INNER JOIN  UTV80.TINLOC ON UTV80.TINWSF.TINWSF_IS_NUMBER = UTV80.TINLOC.TINWSF_IS_NUMBER  INNER JOIN  UTV80.TSASMPPT ON UTV80.TINWSF.TINWSF_IS_NUMBER = UTV80.TSASMPPT.TINWSF0IS_NUMBER  INNER JOIN  UTV80.TSASAMPL ON UTV80.TSASMPPT.TSASMPPT_IS_NUMBER = UTV80.TSASAMPL.TSASMPPT_IS_NUMBER  INNER JOIN  UTV80.TSASAR ON UTV80.TSASAMPL.TSASAMPL_IS_NUMBER = UTV80.TSASAR.TSASAMPL_IS_NUMBER  INNER JOIN  UTV80.TSAANLYT ON UTV80.TSASAR.TSAANLYT_IS_NUMBER = UTV80.TSAANLYT.TSAANLYT_IS_NUMBER WHERE  (UTV80.TINWSYS.D_PRIN_CNTY_SVD_NM LIKE '%CACHE COUNTY%')   AND (UTV80.TSAANLYT.NAME LIKE '%NITRATE%' OR UTV80.TSAANLYT.NAME LIKE '%NITRITE%' OR UTV80.TSAANLYT.NAME LIKE '%AMMONI%' OR UTV80.TSAANLYT.NAME LIKE '%SULFATE%' OR UTV80.TSAANLYT.NAME LIKE '%TDS%' OR UTV80.TSAANLYT.NAME LIKE '%SODIUM%' OR UTV80.TSAANLYT.NAME LIKE '%FLUORIDE%' OR UTV80.TSAANLYT.NAME LIKE '%MAGNESIUM%' OR UTV80.TSAANLYT.NAME LIKE '%SELENIUM%' OR  UTV80.TSAANLYT.NAME LIKE '%CALCIUM%' OR UTV80.TSAANLYT.NAME LIKE '%CHLORIDE%' OR UTV80.TSAANLYT.NAME LIKE '%POTASSIUM%' OR UTV80.TSAANLYT.NAME LIKE '%SELENIUM%' OR UTV80.TSAANLYT.NAME LIKE '%SILICA%' OR UTV80.TSAANLYT.NAME LIKE '%IRON %' OR UTV80.TSAANLYT.NAME LIKE '%ALKA %' OR UTV80.TSAANLYT.NAME LIKE '%CONDUCTIVITY%' OR UTV80.TSAANLYT.NAME LIKE '%PH %' OR UTV80.TSAANLYT.NAME LIKE '%TEMP%' OR UTV80.TSAANLYT.NAME LIKE '%ARSENIC%' OR UTV80.TSAANLYT.NAME LIKE '%CARBON%' OR UTV80.TSAANLYT.NAME LIKE '%TRITIUM%' OR UTV80.TSAANLYT.NAME LIKE '%COPPER%' OR UTV80.TSAANLYT.NAME LIKE '%LEAD%' OR UTV80.TSAANLYT.NAME LIKE '%NITROGEN%' OR UTV80.TSAANLYT.NAME LIKE '%PHOSPHATE%' OR UTV80.TSAANLYT.NAME LIKE '%TDS%' OR UTV80.TSAANLYT.NAME LIKE '%ZINC%' OR UTV80.TSAANLYT.NAME LIKE '%IRON%' OR UTV80.TSAANLYT.NAME LIKE '%CHROMIUM%' ) ORDER BY UTV80.TINWSF.ST_ASGN_IDENT_CD\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SDWIS = pd.read_csv(SDWISFile)\n",
    "\n",
    "def sampid(x):\n",
    "    return \"SDWIS\" + str(x[0]) + str(x[1]) + str(x[2])[:-7]\n",
    "\n",
    "def statid(x):\n",
    "    return \"SDWIS\" + str(x[0]) + str(x[1]) \n",
    "\n",
    "def statnm(x):\n",
    "    return str(str(x[0]) + \" \" + str(x[1])).title()\n",
    "\n",
    "SDWIS[\"StationId\"] = SDWIS[[\"FED_NM\",\"ST_ID\"]].apply(lambda x: statid(x),1)\n",
    "SDWIS[\"StationName\"] = SDWIS[[\"SYS_NM\",\"FAC_NM\"]].apply(lambda x: statnm(x),1)\n",
    "SDWIS[\"SampleId\"] = SDWIS[[\"FED_NM\",\"ST_ID\",\"DTE\"]].apply(lambda x: sampid(x),1)\n",
    "SDWIS[\"OrgId\"] = \"UDDW\"\n",
    "SDWIS[\"OrgName\"] = \"Utah Division of Drinking Water\"\n",
    "SDWIS[\"Elev\"] = SDWIS[\"Z\"].apply(lambda x: round(x*3.2808,1),1)\n",
    "SDWIS[\"Unit\"] = SDWIS[\"UOM_CODE\"].apply(lambda x: str(x).lower(),1)\n",
    "SDWIS[\"MDLUnit\"] = SDWIS[\"DET_UOM\"].apply(lambda x: str(x).lower(),1)\n",
    "SDWIS[\"Param\"] = SDWIS[\"ANLY_NM\"].apply(lambda x: str(x).title().rstrip(),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SDWISFields ={\"DTE\":\"SampleDate\", \"TYPE_CODE\":\"StationType\",\n",
    "              \"CONC_MSR\":\"ResultValue\", \"DET_LIM\":\"MDL\",\n",
    "              \"Y\":\"Lat_Y\", \"X\":\"Lon_X\"}  \n",
    "SDWIS.rename(columns=SDWISFields,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sorted(list(SDWIS.Param.unique()))\n",
    "\n",
    "def parnormSDWIS(x):\n",
    "    p = str(x[0]).rstrip().lstrip().lower()\n",
    "    u = str(x[2]).rstrip().lstrip().lower()\n",
    "    if p == 'nitrate':\n",
    "        return 'Nitrate', x[1]*4.427, 'mg/l'\n",
    "    elif p == 'nitrite':\n",
    "        return 'Nitrite', x[1]*3.285, 'mg/l'\n",
    "    elif p == 'nitrogen-ammonia as (n)':\n",
    "        return 'Ammonium', x[1]*1.288, 'mg/l'\n",
    "    elif u == 'ug/l':\n",
    "        return x[0], x[1]/1000, 'mg/l'\n",
    "    else:\n",
    "        return x[0], x[1], str(x[2]).rstrip()\n",
    "    \n",
    "SDWIS['Param'], SDWIS['ResultValue'], SDWIS['Unit'] = zip(*SDWIS[['Param','ResultValue','Unit']].apply(lambda x: parnormSDWIS(x),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SDWIS.drop([\"FED_NM\", \"DET_UOM\", \"UOM_CODE\",\"ANLY_NM\", \"FAC_NM\", \"ST_ID\", \n",
    "            \"SYS_NM\", \"COUNTY\", \"SY_NBR\", \"Z\", \"ID_NUM\"],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SDWISPmatch = {\"Ph\":\"pH\",\"Tds\":\"TDS\",\"Nitrogen-Ammonia As (N)\":\"Nitrogen-Ammonia as (N)\",\n",
    "              \"Hydroxide As Calcium Carbonate\":\"Hydroxide as Calcium Carbonate\",\n",
    "               \"Bicarbonate As Hco3\":\"Bicarbonate as HCO3\"}\n",
    "SDWIS[\"Param\"] = SDWIS[\"Param\"].apply(lambda x: SDWISPmatch.get(x,x))\n",
    "SDWIS[\"StationName\"] = SDWIS[\"StationName\"].apply(lambda x: x.replace(\"Wtp\",\"WTP\"))\n",
    "#SDWIS[\"Unit\"] = SDWIS[\"Unit\"].apply(lambda x: x.rstrip(),1)\n",
    "SDWIS[\"ResultValue\"] = SDWIS[[\"ResultValue\",\"Unit\"]].apply(lambda x: x[0]/1000 if x[1]==\"ug/L\" else x[0], 1)\n",
    "#SDWIS[\"Unit\"] = SDWIS[\"Unit\"].apply(lambda x: unitfix(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SDWISType = {\"SP\":\"Spring\",\"WL\":\"Well\",\"TP\":\"Facility Other\",\"IN\":\"Stream\",\"CC\":\"Connection\"}\n",
    "SDWIS.StationType = SDWIS.StationType.apply(lambda x: SDWISType.get(x,x),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDWIS facility type code (FacTypeCode): CC, Consecutive_connection;\n",
    "CH, Common_headers; CS, Cistern; CW, Clear_well;\n",
    "DS, Distribution_system_zone; IG, Infiltration_gallery; IN,\n",
    "Intake; NP, Non-piped; OT, Other; PC, Pressure_control;\n",
    "PF, Pump_facility; RC, Roof_catchment; RS, Reservoir; SI,\n",
    "Surface_impoundment; SP, Spring; SS, Sampling_station; ST,\n",
    "Storage; TM, Transmission_main; TP, Treatment_plant; WH,\n",
    "Well_head; WL, Well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SDWISSta = SDWIS.drop([u'SampleDate', u'ResultValue', u'MDL', u'SampleId', u'Unit', u'MDLUnit', u'Param'], axis=1)\n",
    "SDWISSta.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SDWISRes = SDWIS.drop([u'StationType', u'Lat_Y', u'Lon_X', u'StationName', u'Elev'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##UDAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AGStat = pd.read_csv(AGStationsFile)\n",
    "AGStat[\"StationType\"] = \"Well\"\n",
    "AGStatFields = {\"SITEID\":\"StationId\",\"FINISHEDDE\":\"Depth\",\"POINT_Y\":\"Lat_Y\",\n",
    "                \"POINT_X\":\"Lon_X\",\"ELEV_FT\":\"Elev\",\"ACCURACY\":\"HorAcc\"}\n",
    "AGStat.rename(columns=AGStatFields,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AGStat.drop([\"OBJECTID_1\", \"OBJECTID\", \"PUB_YR\", \"SAMPLENO\", \"WLDATE\", \"WLDEPTH\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AGStat.StationId = AGStat.StationId.apply(lambda x: \"UDAF-\"+str(int(x)).zfill(5),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = [\"SampleId\",\"ResultValue\", \"ParAbb\", \"Unit\", \"Param\", \"MDL\",\"BelowLim\",\"TestNo\",\n",
    "         \"StationId\",\"SampleDate\",\"SampYear\"]\n",
    "AGRes = pd.read_csv(AGResultsFile, names=names, index_col=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AGRes[\"DetectCond\"] = AGRes[\"BelowLim\"].apply(lambda x: 'Not Detected' if x=='Y' else np.nan,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AGRes.ResultValue = AGRes[[\"BelowLim\",\"ResultValue\"]].apply(lambda x: np.nan if x[0]==\"Y\" or x[1] == 0.0 else x[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parnormAG(x):\n",
    "    p = str(x[0]).rstrip().lstrip().lower()\n",
    "    u = str(x[2]).rstrip().lstrip().lower()\n",
    "    if p == 'nitrate-n':\n",
    "        return 'Nitrate', x[1]*4.427, 'mg/l'\n",
    "    elif u == 'ug/l':\n",
    "        return x[0], x[1]/1000, 'mg/l'\n",
    "    else:\n",
    "        return x[0], x[1], str(x[2]).rstrip()\n",
    "    \n",
    "AGRes['Param'], AGRes['ResultValue'], AGRes['Unit'] = zip(*AGRes[['Param','ResultValue','Unit']].apply(lambda x: parnormAG(x),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AGRes.Unit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AGRes.dropna(subset=[\"StationId\",\"ResultValue\"], how=\"any\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AGRes.StationId = AGRes.StationId.apply(lambda x: \"UDAF-\"+str(int(x)).zfill(5),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AGStAv = list(AGStat.StationId.values)\n",
    "AGRes = AGRes[AGRes.StationId.isin(AGStAv)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AGStat['OrgId']='UDAF'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##STORET Legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STORLegSta = pd.read_table(STORLegStatFile, skiprows=[1])\n",
    "STORLegRes = pd.read_table(STORLegResFile, skiprows=[1])\n",
    "STORParam = pd.read_table(STORParamFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rescol = list(STORLegRes.columns)\n",
    "j = []\n",
    "for i in rescol:\n",
    "    j.append(i.rstrip(\"\\t\").rstrip().lstrip().replace(\" \",\"\"))\n",
    "resdict = dict(zip(rescol,j))\n",
    "STORLegRes.rename(columns=resdict,inplace=True)\n",
    "\n",
    "statcol = list(STORLegSta.columns)\n",
    "k = []\n",
    "for i in statcol:\n",
    "    k.append(i.rstrip(\"\\t\").rstrip().lstrip().replace(\" \",\"\"))\n",
    "statdict = dict(zip(statcol,k))\n",
    "STORLegSta.rename(columns=statdict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STORLegRes[\"SampleDate\"] = STORLegRes[[\"StartDate\",\"StartTime\"]].apply(lambda x: datetimefix(x,\"%Y-%m-%d %H:%M\"),1)\n",
    "STORLegRes = STORLegRes[STORLegRes.SecondaryActivityCategory.isin(['Water',np.nan])]\n",
    "STORParamDict = dict(zip(STORParam['Parameter No.'].values, STORParam['Full Name'].values))\n",
    "STORLegRes.Param = STORLegRes.Param.apply(lambda x: STORParamDict.get(x),1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STORResField = {\"Agency\":\"OrgId\",\"AgencyName\":\"OrgName\",\"Station\":\"StationId\",\"SampleDepth\":\"SampDepth\"}\n",
    "STORLegRes.rename(columns=STORResField,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STORLegRes.drop([\"StateName\", \"CountyName\", \"HUC\", \"EndDate\", \"UMK\", \"CS\", \"ReplicateNumber\",\n",
    "                 \"COMPOSITE_GRAB_NUMBER\",\"CM\",\"PrimaryActivityCategory\",\"PrimaryActivityCategory\",\n",
    "                 \"SecondaryActivityCategory\",\n",
    "                 \"EndTime\", \"StartDate\", \"StartTime\", \"Latitude\", \"Longitude\"],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STORLegRes[\"SampleId\"] = STORLegRes[[\"StationId\",\"SampleDate\"]].apply(lambda x: str(x[0]) + \"-\" + str(x[1]),1 )\n",
    "STORLegRes[\"StationId\"] = STORLegRes[\"StationId\"].apply(lambda x: \"EPALeg-\" + x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STORLegRes.Param = STORLegRes.Param.apply(lambda x: str(x).title(),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STORLegRes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parnormSTOR(x):\n",
    "    p = str(x[0]).rstrip().lstrip().lower()\n",
    "    if p ==  'nitrate nitrogen, total (mg/L as n)' or p== 'nitrate nitrogen, total':\n",
    "        return 'Nitrate', x[1]*4.427, 'mg/l'\n",
    "    elif p == 'nitrite nitrogen, total (mg/l as n)':\n",
    "        return 'Nitrite', x[1]*3.285, 'mg/l'\n",
    "    elif p == 'nitrogen, ammonia, total (mg/l as n)':\n",
    "        return 'Ammonium', x[1]*1.288, 'mg/l'\n",
    "    elif p == 'sulfate (as s) whole     water, mg/L':\n",
    "        return 'Sulfate', x[1]*2.996, 'mg/l'\n",
    "    elif p in ('phosphorus, dissolved orthophosphate (mg/l as p)'):\n",
    "        return 'Phosphate', x[1]*3.066, 'mg/l'\n",
    "    else:\n",
    "        return x[0], x[1], np.nan\n",
    "\n",
    "STORLegRes['Param'], STORLegRes['ResultValue'], STORLegRes['Unit'] = zip(*STORLegRes[['Param','ResultValue']].apply(lambda x: parnormSTOR(x),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STORKeepers = ['Temperature, Water (Degrees Centigrade)',\n",
    "               'Temperature, Water (Degrees Fahrenheit)', \n",
    "               'Specific Conductance,Field (Umhos/Cm @ 25C)',\n",
    "               'Specific Conductance (Umhos/Cm @ 25C)', \n",
    "               'Sulfate (As S) Whole     Water, Mg/L',\n",
    "               'Oxygen, Dissolved                             Mg/L',\n",
    "               'Oxygen, Dissolved, Percent Of Saturation         %',\n",
    "               'Bod, 5 Day, 20 Deg C                          Mg/L',\n",
    "               'Ph (Standard Units)', 'Ph, Lab, Standard Units                         Su',\n",
    "               'Carbon Dioxide (Mg/L As Co2)', 'Alkalinity,Total,Low Level Gran Analysis     Ueq/L',\n",
    "               'Alkalinity, Total (Mg/L As Caco3)', 'Bicarbonate Ion (Mg/L As Hco3)', 'Carbonate Ion (Mg/L As Co3)',\n",
    "               'Nitrogen, Ammonia, Total (Mg/L As N)', 'Ammonia, Unionzed                      (Mg/L As N)',\n",
    "               'Nitrite Nitrogen, Total (Mg/L As N)', 'Ammonia, Unionized (Calc Fr Temp-Ph-Nh4)  (Mg/L)',\n",
    "               'Nitrate Nitrogen, Total (Mg/L As N)', 'Nitrogen, Kjeldahl, Total, (Mg/L As N)',\n",
    "               'Nitrite Plus Nitrate, Total 1 Det. (Mg/L As N)', 'Phosphorus (P), Water, Total Recoverable      Ug/L',\n",
    "               'Phosphorus, Total (Mg/L As P)', 'Phosphorus, Dissolved Orthophosphate (Mg/L As P)',\n",
    "               'Carbon, Dissolved Organic (Mg/L As C)',\n",
    "               'Carbon, Dissolved Inorganic (Mg/L As C)',\n",
    "               'Hardness, Total (Mg/L As Caco3)', 'Calcium (Mg/L As Caco3)',\n",
    "               'Calcium, Dissolved (Mg/L As Ca)',\n",
    "               'Magnesium, Dissolved (Mg/L As Mg)',\n",
    "               'Sodium, Dissolved (Mg/L As Na)',\n",
    "               'Potassium, Dissolved (Mg/L As K)',\n",
    "               'Chloride, Dissolved In Water           Mg/L',\n",
    "               'Sulfate, Dissolved (Mg/L As So4)',\n",
    "               'Fluoride, Dissolved (Mg/L As F)',\n",
    "               'Silica, Dissolved (Mg/L As Si02)',\n",
    "               'Arsenic, Dissolved  (Ug/L As As)', 'Arsenic, Total (Ug/L As As)',\n",
    "               'Barium, Dissolved (Ug/L As Ba)', 'Barium, Total (Ug/L As Ba)',\n",
    "               'Beryllium, Total (Ug/L As Be)', 'Boron, Dissolved (Ug/L As B)',\n",
    "               'Boron, Total (Ug/L As B)', 'Cadmium, Dissolved (Ug/L As Cd)',\n",
    "               'Cadmium, Total (Ug/L As Cd)', 'Chromium, Dissolved (Ug/L As Cr)',\n",
    "               'Chromium, Hexavalent (Ug/L As Cr)', 'Chromium, Total (Ug/L As Cr)',\n",
    "               'Copper, Dissolved (Ug/L As Cu)', 'Copper, Total (Ug/L As Cu)',\n",
    "               'Iron, Dissolved (Ug/L As Fe)', 'Lead, Dissolved (Ug/L As Pb)',\n",
    "               'Lead, Total (Ug/L As Pb)', 'Manganese, Total (Ug/L As Mn)',\n",
    "               'Manganese, Dissolved (Ug/L As Mn)', 'Thallium, Total (Ug/L As Tl)',\n",
    "               'Nickel, Dissolved (Ug/L As Ni)', 'Nickel, Total (Ug/L As Ni)',\n",
    "               'Silver, Dissolved (Ug/L As Ag)', 'Silver, Total (Ug/L As Ag)',\n",
    "               'Zinc, Dissolved (Ug/L As Zn)', 'Zinc, Total (Ug/L As Zn)',\n",
    "               'Antimony, Total (Ug/L As Sb)', 'Aluminum, Total (Ug/L As Al)',\n",
    "               'Selenium, Dissolved (Ug/L As Se)', 'Selenium, Total (Ug/L As Se)',\n",
    "               'Tritium (1H3),Total (Picocuries/Liter)',\n",
    "               'Hardness, Ca Mg Calculated (Mg/L As Caco3)',\n",
    "               'Chlorine, Total Residual (Mg/L)',\n",
    "               'Residue,Total Filtrable (Dried At 180C),Mg/L',\n",
    "               'Nitrate Nitrogen, Dissolved (Mg/L As No3)', 'Iron (Ug/L As Fe)',\n",
    "               'Phosphorus, Total, As Po4 - Mg/L', 'Mercury, Total  (Ug/L As Hg)']\n",
    "STORLegRes = STORLegRes[STORLegRes.Param.isin(STORKeepers)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parsplit(x,p):\n",
    "    x = str(x).rstrip().lstrip()\n",
    "    if p == \"Un\":\n",
    "        z = -1\n",
    "        x = str(x).replace(\"Mg/L\", \"mg/l\")\n",
    "        x = str(x).replace(\"Ug/L\", \"ug/l\")\n",
    "        x = str(x).replace(\"o\", \"O\")\n",
    "        x = str(x).replace(\"c\", \"C\")\n",
    "        x = str(x).replace(\"TOtal ReCOverable\",\"Total Recoverable\")        \n",
    "        x = str(x).replace(\"UmhOs\", \"umhos\")\n",
    "        x = str(x).replace(\"TOtal\",\"Total\")\n",
    "    elif p== \"Par\":\n",
    "        z = 0\n",
    "        x = str(x).replace(\", Standard Units\",\"\")\n",
    "        x = str(x).replace(\", Unionized\",\"\")\n",
    "        x = str(x).replace(\", Unionzed\",\"\")\n",
    "        x = str(x).replace(\",Low Level Gran Analysis\",\"\")\n",
    "        x = str(x).replace(\" Ion\",\"\")\n",
    "        x = str(x).replace(\",Total\",\", Total\")\n",
    "        if x == \"Ph\" or x == \"Ph, Lab\":\n",
    "            x = str(x).replace(\"Ph\",\"pH\")\n",
    "    if \"(\" in x:\n",
    "        x = str(x).replace(\" As \", \" as \")\n",
    "        return str(x).split(\" (\")[z].rstrip(\")\").rstrip().lstrip()\n",
    "    else:\n",
    "        return str(x).split(\"  \")[z].rstrip().lstrip()\n",
    "\n",
    "def splitmore(x):\n",
    "    if \"NO3\" in x:\n",
    "        return x\n",
    "    elif \" as \" in x:\n",
    "        return x.split(\" as \")[0]\n",
    "    elif x == \"As S) WhOle     Water, mg/l\" or x == \"Dried At 180C),mg/l\" or x==\"PhOsphOrus, Total, As PO4 - mg/l\":\n",
    "        return \"mg/l\"\n",
    "    elif x == \"P), Water, Total Recoverable      ug/l\":\n",
    "        return \"ug/l\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def unitconv(x):\n",
    "    if x[1]==\"ug/l\":\n",
    "        return x[0]/1000\n",
    "    elif x[1]==\"Degrees Fahrenheit\":\n",
    "        return (float(x[0])-32.0)*(5.0/9.0)\n",
    "    else:\n",
    "        return x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STORLegRes[\"Unit\"] = STORLegRes[\"Param\"].apply(lambda x: parsplit(x,\"Un\"), 1)\n",
    "STORLegRes[\"Param\"] = STORLegRes[\"Param\"].apply(lambda x: parsplit(x,\"Par\"), 1)\n",
    "STORLegRes[\"Unit\"] = STORLegRes[\"Unit\"].apply(lambda x: splitmore(x), 1)\n",
    "STORLegRes[\"ResultValue\"] = STORLegRes[[\"ResultValue\",\"Unit\"]].apply(lambda x: unitconv(x), 1)\n",
    "STORLegRes[\"Unit\"] = STORLegRes[\"Unit\"].apply(lambda x: \"mg/l\" if x==\"ug/l\" else x, 1)\n",
    "STORLegRes[\"Unit\"] = STORLegRes[\"Unit\"].apply(lambda x: \"Degrees Centigrade\" if x==\"Degrees Fahrenheit\" else x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STORStaField = {\"Agency\":\"OrgId\",\"AgencyName\":\"OrgName\",\"Station\":\"StationId\", \"DepthUnits\":\"DepthUnit\",\n",
    "                \"Latitude\":\"Lat_Y\", \"Longitude\":\"Lon_X\", \"HUC\":\"HUC8\", \"StationDepth\":\"Depth\"}\n",
    "STORLegSta.rename(columns=STORStaField,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STORLegSta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STORLegSta.drop([\"RchmileSegment\", \"MilesUpReach\", \"Rchonoff\", \"Description\", \"G\", \"S\", \"StationAlias\",\n",
    "                 \"Rchname\", \"StateName\", \"CountyName\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STORLegSta.StationType = STORLegSta.StationType.apply(lambda x: str(x).rstrip(\" \").strip(\"/SUPPLY\").split(\"/\")[-1].title(),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LegTypeDict = {\"We\":\"Well\"}\n",
    "STORLegSta.StationType = STORLegSta.StationType.apply(lambda x: LegTypeDict.get(x,x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STORLegSta.StationId = STORLegSta[\"StationId\"].apply(lambda x: \"EPALeg-\" + x, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##UGS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UGSfield = pd.read_excel(fielddata,\"FieldChem\")\n",
    "UGSNO3 = pd.read_excel(fielddata,\"Nitrate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UGS = pd.read_csv(UGSFile, engine=\"python\")\n",
    "UGS[\"StationId\"] = UGS[\"SITE\"].apply(lambda x:\"UGS-\"+str(x).zfill(4),1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UGSSta = UGS.drop([u'OBJECTID_1',u'SITE', u'TDS', u'Temp', u'Cond', u'CO2', u'HCO3', \n",
    "                  u'CO3',u'Na', u'pH', u'Ca', u'SO4', u'NO3', u'As_', u'Cl', u'K',\n",
    "                  u'Mg', u'Hard', u'NH4'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UGSRe = UGS.drop([u'OBJECTID_1',u'SITE',u'StationType', u'Geology', u'Elev', u'Lat_Y', u'Lon_X', u'StationName', \n",
    "                  u'OrgId', u'WRNUM', u'SITE', u'UTM_X', u'UTM_Y', u'Depth_ft'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UGSRe[\"SampleId\"] = UGSRe.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UGSRe.reset_index(inplace=True)\n",
    "UGSRe.set_index([\"StationId\",\"SampleId\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UGSRe.drop(UGSRe.columns[0],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UGSStack = UGSRe.stack().to_frame()\n",
    "UGSStack.columns = [\"ResultValue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UGSStack.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UGSStack.columns=[\"StationId\",\"SampleId\",\"Param\",\"ResultValue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unitcon(x):\n",
    "    if x==\"pH\":\n",
    "        return \"\"\n",
    "    elif x==\"Temp\":\n",
    "        return \"C\"\n",
    "    elif x==\"Cond\":\n",
    "        return \"uS/cm\"\n",
    "    else:\n",
    "        return \"mg/l\"\n",
    "    \n",
    "UGSStack[\"Unit\"] = UGSStack[\"Param\"].apply(lambda x: unitcon(x),1)\n",
    "UGSStack[\"ParAbb\"] = UGSStack[\"Param\"]\n",
    "UGSStack[\"OrgId\"] = \"UGS\"\n",
    "UGSStack[\"OrgName\"] = \"Utah Geological Survey\"\n",
    "UGSStack[\"ResultValue\"] = UGSStack[['Param','ResultValue']].apply(lambda x: x[1]*1.288 if x[0]=='Ammonia as N' else x[1],1)\n",
    "UGSStack[\"Param\"] = UGSStack['Param'].apply(lambda x: 'Ammonia' if x=='Ammonia as N' else x, 1)\n",
    "UGSStack[\"ResultValue\"] = UGSStack[['Param','ResultValue']].apply(lambda x: x[1]*3.066 if x[0]=='Phosphate, Tot. Dig. (as P)' else x[1],1)\n",
    "UGSStack[\"Param\"] = UGSStack['Param'].apply(lambda x: 'Phosphate' if x=='Phosphate, Tot. Dig. (as P)' else x, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##State Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SLSampMatch = pd.read_excel(fielddata,\"StateLabMatch\")\n",
    "SLStations = pd.read_excel(fielddata,\"Stations\")\n",
    "SLStat = pd.merge(SLSampMatch, SLStations, on='StationId', how='left')\n",
    "#SLStat.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SLRes[np.isnan(SLRes.ResultValue)].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SL0 = pd.read_table(statelabresults0, sep=\"\\t\", lineterminator=\"\\n\", error_bad_lines=False)\n",
    "SL0 = SL0[SL0['Collector']=='PI']\n",
    "SL1 = pd.read_table(statelabresults1, sep=\"\\t\", lineterminator=\"\\n\", error_bad_lines=False)\n",
    "SL1 = SL1[SL1['Collector']=='PI']\n",
    "SL2 = pd.read_table(statelabresults2, sep=\"\\t\", lineterminator=\"\\n\", error_bad_lines=False)\n",
    "SL2 = SL2[SL2['Collector']=='PI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SL = pd.concat([SL0,SL1,SL2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SL[\"OrgId\"] = \"UGS\"\n",
    "SL[\"OrgName\"] = \"Utah Geological Survey\"\n",
    "SL['DetectCond'] = SL['Problem#Identifier'].apply(lambda x: 'Not Detected' if str(x).rstrip()=='<' else np.nan,1)\n",
    "SL['SampleDate'] = SL[['Sample#Date','Sample#Time']].apply(lambda x: datetimefix(x,\"%m/%d/%y %H:%M\"),1)\n",
    "SLHead = {'Sample#Number':'SampleId', 'Param#Description':'Param', 'Result#Value':'ResultValue','Units':'Unit', \n",
    "          'Lower#Report#Limit':'MDL','Method#ID':'SampMeth','Analysis#Date':'AnalysisDate'}\n",
    "SL.rename(columns=SLHead,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SL.drop([u'Lab#Code', u'Station#ID', u'Source#Code', u'Sample#Date',\n",
    "       u'Sample#Time', u'Sample#Type', u'Cost#Code', u'Billing#Code',\n",
    "       u'Agency#Bill#Code', u'Trip#ID', u'Sample#Description', u'Collector',\n",
    "       u'Sample#Recieved#Date', u'Chain#of#Custody#Ind.', u'Replicate#Number',\n",
    "       u'Sample#Comment', u'Method#Number', u'Method#Agency',\n",
    "       u'Method#Description', u'Param#Number', u'CAS#Number',\n",
    "       u'Matrix#Number', u'Matrix#Description', u'Preparation#Date',\n",
    "       u'Problem#Identifier', u'Result#Code', \n",
    "       u'Upper#Quant#Limit', u'Method#Detect#Limit',\n",
    "       u'Confidence#Limit', u'%#Confidence#Limit',u'Dilution#Factor',\n",
    "       u'Batch#Number',u'Comment#Number', u'Comment#Text'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SL.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SLRes = pd.merge(SL, SLStat, on='SampleId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SLRes.drop([u'StationName', u'Elev', u'Lat_Y', u'Lon_X', u'Depth', \n",
    "            u'DepthUnit',  u'ScreenDepth', u'WIN', u'Diameter', u'WL', u'WLDate', u'ScreenBottom'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SLStat.drop(['SampleId'],inplace=True, axis=1)\n",
    "SLStat.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def SLparnorm(x):\n",
    "    p = str(x[0]).rstrip().lstrip().lower()\n",
    "    u = str(x[2]).rstrip().lstrip().lower()\n",
    "    if p == 'nitrate nitrogen, total (mg/l as n)':\n",
    "        return 'Nitrate', x[1]*4.427, 'mg/l'\n",
    "    elif p == 'nitrite nitrogen, total (mg/l as n)':\n",
    "        return 'Nitrite', x[1]*3.285, 'mg/l'\n",
    "    elif p == 'ammonia as n':\n",
    "        return 'Ammonium', x[1]*1.288, 'mg/l'\n",
    "    elif p == 'sulfate (as s) whole     water, mg/L':\n",
    "        return 'Sulfate', x[1]*2.996, 'mg/l'\n",
    "    elif p in ('phosphate, tot. dig. (as p)', 'phosphate-phosphorus as p','orthophosphate as p'):\n",
    "        return 'Phosphate', x[1]*3.066, 'mg/l'\n",
    "    elif u == 'ug/l':\n",
    "        return x[0], x[1]/1000, 'mg/l'\n",
    "    else:\n",
    "        return x[0], x[1], str(x[2]).rstrip()\n",
    "\n",
    "def MDLfix(x):\n",
    "    u = str(x[1]).rstrip().lstrip().lower()\n",
    "    if np.isfinite(x[2]):\n",
    "        return x[0]\n",
    "    elif u=='ug/l':\n",
    "        return x[0]/1000\n",
    "    else:\n",
    "        return x[0]\n",
    "\n",
    "\n",
    "SLRes['MDL'] = SLRes[['MDL','Unit','ResultValue']].apply(lambda x: MDLfix(x),1)\n",
    "SLRes['Param'], SLRes['ResultValue'], SLRes['Unit'] = zip(*SLRes[['Param','ResultValue','Unit']].apply(lambda x: parnorm(x),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Res = pd.concat([STORLegRes,AGRes,SDWISRes,WQP,UGSStack,SLRes,UGSfield,UGSNO3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Res = Res[~Res[\"Unit\"].isin(['ueq/L','Ueq/L','ueq/l','tons/ac ft','tons/day','meq/L'])]\n",
    "Res = Res[~Res[\"Param\"].isin([\"Heptachlorobiphenyl\", \"Hydrocarbons\", \"Hydroxide\", \"Ionic strength\",\n",
    "                              \"Floating debris, severity\", \"Carbon Tetrachloride\", \"Trichlorobiphenyl\",\n",
    "                              \"Vinyl Chloride\", \"True color\", \"Color\", \"Trash, Debris, Floatables\",\n",
    "                              \"Total volatile solids\", \"Temperature, air\", \"Residue, Total Filtrable\",\n",
    "                              \"Pentachlorobiphenyl\", \"Odor threshold number\", \"Odor, atmospheric\",\n",
    "                              \"Instream features, est. stream width\", \"Hydroxide\", \n",
    "                              \"Light, transmissivity\",\"Algae, floating mats (severity)\"])]\n",
    "len(Res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Res[[\"Param\",\"Unit\",\"USGSPCode\"]].drop_duplicates(subset=[\"Param\",\"Unit\"]).sort([\"Param\"]).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Stat = pd.concat([STORLegSta, AGStat, SDWISSta, WQPStat, SLStat, UGSSta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parmatch = pd.read_excel(rootname + \"Aquachem.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parmatch.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parmatchdict = dict(zip(parmatch.Param.values, parmatch.ParrAbb.values))\n",
    "Res[\"ParAbb\"] = Res[[\"ParAbb\",\"Param\"]].apply(lambda x: parmatchdict.get(x[1],x[0]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = Res.dropna(subset=[\"StationId\",\"Param\",\"SampleId\"], how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Stat[\"StationName\"] = Stat[\"StationName\"].apply(lambda x: str(x).strip().lstrip().rstrip(),1)\n",
    "results[\"Unit\"] = results[[\"ParAbb\",\"Unit\"]].apply(lambda x: \"C\" if x[0]==\"Temp\" else x[1],1)\n",
    "results[\"Unit\"] = results[[\"ParAbb\",\"Unit\"]].apply(lambda x: \"umhos/cm\" if x[0]==\"Cond\" else x[1],1)\n",
    "results[\"Unit\"] = results[[\"ParAbb\",\"Unit\"]].apply(lambda x: \"\" if x[0]==\"pH\" else x[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.drop([\"AnalysisDate\",\"AnalytMeth\",\"SampType\",\"AnalytMethId\", \"BelowLim\", \"StationName\",\n",
    "              \"MethodDescript\", \"LabComments\", \"LabName\", \"LimitType\", \"ProjectId\", \"QualCode\",\n",
    "              \"OrgName\",\"R\", \"ResultComment\",\"ResultStatus\",\"SampComment\", \"SampEquip\", \n",
    "              \"SampDepthRef\", \"SampDepthU\",\"SampDepth\",\"SampType\", \"USGSPCode\",\n",
    "              \"SampMeth\", \"SampMethName\",\"SampYear\",\"TestNo\"],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aquc = results[[\"Param\",\"OrgId\",\"Unit\",\"ParAbb\"]]\n",
    "aquc.drop_duplicates([\"Param\",\"Unit\"],inplace=True)\n",
    "aquc.sort([\"Param\"],inplace=True)\n",
    "aquc.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estsize(df):\n",
    "    return df.values.nbytes + df.index.nbytes + df.columns.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(str(round(estsize(results)/1E6,2))+\" MB\")\n",
    "#(str(round(estsize(Stat)/1E6,2))+\" MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GWStat = Stat[Stat['StationType'].isin(['Spring','Well'])]\n",
    "GWStatList = list(GWStat.StationId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NDs = {'Not Detected':'<', 'Present Above Quantification Limit':'<', 'ND             ':'<', '*Present >QL   ':'>',\n",
    "       'Present Below Quantification Limit':'<', '*Non-detect    ':'<', 'Detected Not Quantified':'<', \n",
    "       'Systematic Contamination':'<'}\n",
    "results.DetectCond = results.DetectCond.apply(lambda x: NDs.get(x,np.nan),1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GWResNoND = results[(results['StationId'].isin(GWStatList))] \n",
    "GWResNoND = GWResNoND[(~GWResNoND['DetectCond'].isin(['<','>']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_nan(x): \n",
    "    try: \n",
    "        return math.isnan(x) \n",
    "    except: \n",
    "        return False \n",
    "\n",
    "def detected(x):\n",
    "    if x[1]=='<' and np.isfinite(x[0]):\n",
    "        return x[1]+str(x[0])       \n",
    "    elif x[1]=='<' and np.isfinite(x[2]):\n",
    "        if str(x[3]).rstrip().lower() == 'ug/l':\n",
    "            return x[1]+str(x[2]/1000)\n",
    "        else:\n",
    "            return x[1]+str(x[2])\n",
    "    else:\n",
    "        return x[0]\n",
    "\n",
    "results.ResultValue = results[['ResultValue','DetectCond','MDL','MDLUnit']].apply(lambda x: detected(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GWRes = results[results['StationId'].isin(GWStatList)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GWRes.drop_duplicates(subset = ['SampleId','ParAbb'],inplace=True)\n",
    "GWResNoND.drop_duplicates(subset = ['SampleId','ParAbb'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Pivot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datap = GWRes.pivot(index='SampleId', columns='ParAbb', values='ResultValue')\n",
    "datapND = GWResNoND.pivot(index='SampleId', columns='ParAbb', values='ResultValue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datap.dropna(subset=['SO4','Cond','Temp','TDS','pH_field'],how='all',inplace=True)\n",
    "datap.drop(datap.columns[[0]], axis=1, inplace=True)\n",
    "datapND.dropna(subset=['SO4','Cond','Temp','TDS','pH_field'],how='all',inplace=True)\n",
    "datapND.drop(datapND.columns[[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resdrop = [ 'DetectCond',\n",
    "             'MDL', 'MDLUnit',\n",
    "             'OrgId', 'Param',\n",
    "             'ResultValue', 'SampFrac',\n",
    "             'SampMedia', \n",
    "             'Unit', 'ParAbb']\n",
    "resPivot = GWRes.drop(resdrop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapiv = pd.merge(datap, resPivot, left_index=True, right_on='SampleId',how='left')\n",
    "datapivND = pd.merge(datapND, resPivot, left_index=True, right_on='SampleId',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivStats = GWStat.drop(['Aquifer', 'ConstDate', 'Depth', 'DepthUnit','AquiferType', 'OrgName', 'HorCollMeth',\n",
    "                         'HoleDUnit', 'HoleDepth', 'HUC8', 'HorAccUnit',\n",
    "                         'ElevUnit', 'ElevRef', 'ElevAcc', 'ElevMeth','CountyCode', 'ElevAccUnit',\n",
    "                         'HorAcc', 'StateCode', 'HorRef',\n",
    "                         'OrgId', 'StationComment', 'StationName'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pivStats.reset_index(inplace=True)\n",
    "pivStats.set_index(\"StationId\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapiv.drop_duplicates(inplace=True)\n",
    "datapivND.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivdata = pd.merge(datapiv, pivStats, left_on=\"StationId\", right_index=True, how='left')\n",
    "pivdataND = pd.merge(datapivND, pivStats, left_on=\"StationId\", right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivdata.drop_duplicates(inplace=True)\n",
    "pivdataND.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piperdata = pivdata.dropna(subset = ['Ca','Na','Cl','Mg','SO4'],how='any')\n",
    "piperdataND = pivdataND.dropna(subset = ['Ca','Na','Cl','Mg','SO4'],how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piperdata.drop_duplicates(subset=['SampleId'],inplace=True)\n",
    "piperdataND.drop_duplicates(subset=['SampleId'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(str(round(estsize(piperdata)/1E6,2))+\" MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GWStat.drop(['Aquifer','AquiferType','CountyCode','DepthUnit','ElevAcc','ElevAccUnit',\n",
    "             'ElevMeth','ElevRef','ElevUnit','HoleDUnit','HorAcc','HorAccUnit','HorCollMeth',\n",
    "            'HorRef','StateCode'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def proj(x):\n",
    "    inProj = Proj(init='epsg:4326') #WGS84\n",
    "    outProj = Proj(init='epsg:2152') #NAD83(CSRS98) / UTM zone 12N\n",
    "    x2,y2 = transform(inProj,outProj,x[0],x[1])\n",
    "    return x2, y2\n",
    "\n",
    "GWStat['UTM_X'], GWStat['UTM_Y'] = zip(*GWStat[['Lon_X','Lat_Y']].apply(lambda x: proj(x),1))\n",
    "piperdata['UTM_X'], piperdata['UTM_Y'] = zip(*piperdata[['Lon_X','Lat_Y']].apply(lambda x: proj(x),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getelev(x):\n",
    "    elev = \"http://ned.usgs.gov/epqs/pqs.php?x=\"+str(x[0])+\"&y=\"+str(x[1])+\"&units=Meters&output=xml\"\n",
    "    response = urllib2.urlopen(elev)\n",
    "    html = response.read()\n",
    "    d = xmltodict.parse(html)\n",
    "    return float(d['USGS_Elevation_Point_Query_Service']['Elevation_Query']['Elevation'])\n",
    "\n",
    "GWStat['Elev'] = GWStat[['Lon_X','Lat_Y']].apply(lambda x: getelev(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def winmatch(x):\n",
    "    request = mechanize.Request(\"http://waterrights.utah.gov/wellinfo/wellsearch.asp\")\n",
    "    response = mechanize.urlopen(request)\n",
    "    forms = mechanize.ParseResponse(response, backwards_compat=False)\n",
    "    response.close()\n",
    "    form = forms[0] \n",
    "    #print form\n",
    "    form[\"mainoption\"]=[\"radius\"]\n",
    "    form[\"SearchRadius\"]=\"2000\"\n",
    "    form[\"option\"]=[\"UTM\"]\n",
    "    form[\"xUTM\"]=str(x[0])\n",
    "    form[\"yUTM\"]=str(x[1])\n",
    "    if np.isfinite(x[2]):\n",
    "        form[\"DateRange\"]=[\"on\"]\n",
    "        form[\"edtDrillBef\"]=str(int(str(x[2])[:4])+5)\n",
    "        form[\"edtDrillAft\"]=str(int(str(x[2])[:4])-5)\n",
    "        #print str(int(str(x[2])[:4]))\n",
    "    if np.isfinite(x[3]):\n",
    "        form[\"DepthRange\"]=[\"on\"]\n",
    "        form[\"edtDrillBel\"]=str(int(x[3])-10)\n",
    "        form[\"edtDrillAbo\"]=str(int(x[3])+30)\n",
    "        #print str(str(int(x[3])))\n",
    "    win =  mechanize.urlopen(form.click()).read()\n",
    "    winbeg = win.find('WIN=')\n",
    "    if winbeg == -1:\n",
    "        return np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan \n",
    "    else:\n",
    "        wintabeg=win.find('<table',win.find('<table')+5)\n",
    "        wintaend=win.find('</table>')\n",
    "        winmatches = pd.read_html(win[wintabeg:wintaend], header=0, skiprows=0)\n",
    "        winmatches = winmatches[0]\n",
    "        winDic = {u'WRNUM/Appl. No.':'WRNUM',u'Distance From Point (ft)':'DIST',u'Diameter':'Diam',u'Depth':'TD',\n",
    "          u'Drilled Date':'DrillDate',u'Location(link to Log)':'Locatio',u'WIN':'WIN',u'Geologic Log':'Log'}\n",
    "        winmatches.rename(columns=winDic,inplace=True)\n",
    "        return winmatches.ix[0,0], winmatches.ix[0,1], winmatches.ix[0,2], winmatches.ix[0,3], winmatches.ix[0,4], winmatches.ix[0,5], int(winmatches.ix[0,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GWStat.ScreenDepth = GWStat[['ScreenDepth','SCREENDEPT']].apply(lambda x: x[0] if np.isfinite(x[0]) else x[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GWStat.drop_duplicates(['StationId'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GWStat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GWStat.drop([u'Aquifer', u'AquiferType', u'CountyCode',u'ElevAcc', u'ElevAccUnit', u'ElevMeth',\n",
    "             u'ElevRef', u'ElevUnit',u'Geology', u'HUC8', u'HoleDUnit', u'SCREENDEPT',\n",
    "             u'HorAcc', u'HorAccUnit', u'HorCollMeth', u'HorRef'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GWStat['WRNUM2'], GWStat['Dist'], GWStat['Diam'], GWStat['DepthWR'], GWStat['DrillDate'], GWStat['Loc'], GWStat['WIN'] = zip(*GWStat[['UTM_X','UTM_Y','ConstDate','Depth']].apply(lambda x: winmatch(x),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipergrps = piperdataND.groupby(['StationId'], squeeze=True).median()\n",
    "pipergrps.drop(pipergrps.columns[[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GWStat.to_csv(rootname+'GWStations.csv',index_label='objid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipergrps.to_csv(rootname+'avgpiper.csv',index_label='objid')\n",
    "piperdata.to_csv(rootname+'piper.csv',index_label='objid')\n",
    "\n",
    "GWRes.to_csv(rootname+'GWResults.csv',index_label='objid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipergrps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(rootname + \"combined_out.xlsx\", engine=\"xlsxwriter\")\n",
    "Stat.to_excel(writer, \"stations\", index=False)\n",
    "results.to_excel(writer, \"results\", index=False)\n",
    "GWStat.to_excel(writer, 'GWStations',index=False)\n",
    "GWRes.to_excel(writer, 'GWResults',index=False)\n",
    "piperdata.to_excel(writer, \"piperpivot\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(list(results.Param.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Nmed = Nres.groupby(['StationId'])['ResultValue'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Nres.sort(['ResultValue'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
